version: "2"
image_name: minimal-viable-llama-stack-configuration

apis:
  - agents
  - safety
  - vector_io
  - tool_runtime
  - inference
  - telemetry

benchmarks: []
container_image: null
datasets: []
external_providers_dir: null
inference_store:
  db_path: .llama/distributions/ollama/inference_store.db
  type: sqlite
logging: null
metadata_store:
  db_path: .llama/distributions/ollama/registry.db
  namespace: null
  type: sqlite
providers:
  inference:
    - provider_id: openai
      provider_type: remote::openai
      config:
        api_key: ${env.OPENAI_API_KEY}
    - provider_id: my-gemini
      provider_type: remote::gemini
      config:
        api_key: ${env.GOOGLE_API_KEY}
  agents:
    - config:
        persistence_store:
          db_path: .llama/distributions/ollama/agents_store.db
          namespace: null
          type: sqlite
        responses_store:
          db_path: .llama/distributions/ollama/responses_store.db
          type: sqlite
      provider_id: meta-reference
      provider_type: inline::meta-reference
  tool_runtime:
    - provider_id: model-context-protocol
      provider_type: remote::model-context-protocol
      config: {}
  telemetry:
    - config:
        service_name: "lightspeed-stack"
        sinks: sqlite
        sqlite_db_path: .llama/distributions/ollama/trace_store.db
      provider_id: meta-reference
      provider_type: inline::meta-reference
server:
  auth: null
  host: null
  port: 8321
  quota: null
  tls_cafile: null
  tls_certfile: null
  tls_keyfile: null
shields: []
vector_dbs: []
models:
  - model_id: gpt-4o-mini
    provider_id: openai
    model_type: llm
    provider_model_id: gpt-4o-mini
  - model_id: gpt-4o
    provider_id: openai
    model_type: llm
    provider_model_id: gpt-4o
  - model_id: gemini-2.5-flash
    provider_id: my-gemini
